{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipeline_online.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duduteddy/python/blob/master/pipeline_online.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lpzqittiaLdH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Add all relevant imports here\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import xgboost as xgb\n",
        "import sklearn.svm as svm\n",
        "import sklearn.tree as tree\n",
        "import sklearn.ensemble as ensemble\n",
        "import sklearn.neighbors as neighbors\n",
        "import sklearn.naive_bayes as naive_bayes\n",
        "import sklearn.linear_model as linear_model\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn import preprocessing as preproc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import accuracy_score, log_loss, mean_squared_error, mean_absolute_error, roc_curve, auc\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "# # uploaded = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WGANn5lfaQoz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def splitMetaData(row_id):\n",
        "\n",
        "    # Parse data from MetaData\n",
        "    column_key = {'name': 'C', 'columns': 'W',\"preprocessing\":\"AG\", \"Libraries\": \"AS\",'estimator_func_call': 'AU', 'target_name': 'AC', 'output_type': 'AA', 'performance_metric': 'BB', 'feature_selector': 'AL','featureExtractor function call': 'AJ'}\n",
        "    column_key = dict(map(lambda kv: (kv[0], alpha_to_number(kv[1])), column_key.items()))\n",
        "\n",
        "    metadata['competition_name'] = rows.loc[row_id][column_key['name']]\n",
        "    metadata['Libraries'] = rows.loc[row_id][column_key['Libraries']]\n",
        "    metadata['preprocessing'] = rows.loc[row_id][column_key['preprocessing']]\n",
        "    metadata['estimator'] = rows.loc[row_id][column_key['estimator_func_call']]\n",
        "    metadata['target_column'] = rows.loc[row_id][column_key['target_name']]\n",
        "    metadata['output_type'] = rows.loc[row_id][column_key['output_type']].split(',')\n",
        "    metadata['metric'] = rows.loc[row_id][column_key['performance_metric']]\n",
        "    metadata['feature_selector'] = rows.loc[row_id][column_key['feature_selector']]\n",
        "    metadata['featureExtractor'] = rows.loc[row_id][column_key['featureExtractor function call']]\n",
        "    columns = rows.loc[row_id][column_key['columns']]\n",
        "\n",
        "\n",
        "    # Parse column information \n",
        "    numeric_columns = []\n",
        "    unwanted_columns = []\n",
        "    categorical_columns = []\n",
        "    columns_data = [x.strip() for x in columns[1:-1].split(';')]\n",
        "    print('columns_data: ', columns_data)\n",
        "    for ind, val in enumerate(columns_data):\n",
        "        if ind%3 == 2:\n",
        "            if (val == \"numeric\" or val == \"integer\" or val == \"real\"):\n",
        "                numeric_columns.append(columns_data[ind-1])\n",
        "            elif val == \"categorical\":\n",
        "                categorical_columns.append(columns_data[ind-1])\n",
        "            elif val == \"unwanted\" or val == 'dateTime':\n",
        "                unwanted_columns.append(columns_data[ind-1])\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    metadata['numeric_columns'] = numeric_columns\n",
        "    metadata['unwanted_columns'] = unwanted_columns\n",
        "    metadata['categorical_columns'] = categorical_columns\n",
        "\n",
        "    # Remove target from features columns\n",
        "    if metadata['target_column'] in metadata['numeric_columns']:\n",
        "        metadata['numeric_columns'].remove(metadata['target_column'])\n",
        "    if metadata['target_column'] in metadata['categorical_columns']:\n",
        "        metadata['categorical_columns'].remove(metadata['target_column'])\n",
        "    if metadata['target_column'] in metadata['unwanted_columns']:\n",
        "        metadata['unwanted_columns'].remove(metadata['target_column'])\n",
        "\n",
        "    print('competition name :' + metadata['competition_name'])\n",
        "    print('numeric_columns:', metadata['numeric_columns'])\n",
        "    print('categorical_columns:' ,metadata['categorical_columns'])\n",
        "    print('unwanted_columns: ' , metadata['unwanted_columns'])\n",
        "    print('target_column:' ,metadata['target_column'])\n",
        "    print('metric: ' , metadata['metric'])\n",
        "    print('feature_selector: ' , metadata['feature_selector'])\n",
        "    print('featureExtractor', metadata['featureExtractor'])\n",
        "    print('estimator: ' , metadata['estimator'])\n",
        "    print(\"preprocessing: \",metadata['preprocessing'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_l-WwCJaVej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocessing(train_df,test_df=None):\n",
        "    \n",
        "    train_num = train_df.shape[0]\n",
        "    data = pd.concat([train_df,test_df])\n",
        "    if metadata['unwanted_columns']:\n",
        "        data.drop(metadata['unwanted_columns'], axis=1, inplace=True)\n",
        "\n",
        "    X = data.drop(metadata['target_column'], 1)\n",
        "    y = data[metadata['target_column']]\n",
        "        \n",
        "    if 'label encoding' in metadata['preprocessing']:\n",
        "        for c in metadata['categorical_columns']:\n",
        "            lbl = LabelEncoder()\n",
        "            lbl.fit(list(data[c])) \n",
        "            data[c] = lbl.transform(list(data[c]))\n",
        "    \n",
        "\n",
        "    if 'label categorical'in metadata['preprocessing']:\n",
        "        obj=list(data.select_dtypes(include = ['object']).columns)\n",
        "        for c in (obj):\n",
        "            if len(data[c].unique()) == 2:\n",
        "                uni = data[c].unique()[0]\n",
        "                data[c + '_numeric'] = (data[c].values == uni)\n",
        "        data.drop(obj,axis=1,inplace=True)\n",
        "    if 'label target'in metadata['preprocessing']:\n",
        "        lbl_enc = LabelEncoder()\n",
        "        data[metadata['target_column']] = lbl_enc.fit_transform(data[metadata['target_column']].astype(str))\n",
        "    \n",
        "    if 'normalization/scaling' in metadata['preprocessing']:\n",
        "\n",
        "        from sklearn.preprocessing import MinMaxScaler\n",
        "        min_max_scaler = MinMaxScaler()\n",
        "        data = pd.DataFrame(data=min_max_scaler.fit_transform(data),columns=data.columns, index=data.index)\n",
        "      \n",
        "      \n",
        "    if \"nan processing\" in metadata['preprocessing']:\n",
        "        data = data.fillna(0)\n",
        "      \n",
        "      \n",
        "    if 'train test split' in metadata['preprocessing']:\n",
        "\n",
        "        X = data.drop(metadata['target_column'], 1)\n",
        "        if 'log label' in metadata['preprocessing']:\n",
        "          y = data[metadata['target_column']].apply(np.log)\n",
        "        else:\n",
        "          y = data[metadata['target_column']]\n",
        "        \n",
        "        X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "    \n",
        "    else:\n",
        "        train = data[:train_num]\n",
        "        test = data[train_num:]\n",
        "        X_train = data.drop(metadata['target_column'], axis=1)\n",
        "        y_train = data[metadata['target_column']]\n",
        "        y_test = test[metadata['target_column']]\n",
        "        X_test =test.drop(metadata['target_column'],axis=1)\n",
        "        \n",
        "    if 'as type' in metadata['preprocessing']:\n",
        "        X_test = X_test.astype(float)\n",
        "        X_train = X_train.astype(float)\n",
        "        \n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "heRYUTVFaYdA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Feature Extraction\n",
        "def feature_extraction(X_train, X_test, y_train, y_test):\n",
        "    extractor=eval(metadata['featureExtractor'])\n",
        "    if 'countvectorizer' in metadata['featureExtractor'].lower():\n",
        "\n",
        "      X_train = extractor.fit_transform(X_train.values.flatten())\n",
        "      X_test = extractor.transform(X_test.values.flatten())\n",
        "    else:\n",
        "      X_train = extractor.fit_transform(X_train.values)\n",
        "      X_test = extractor.transform(X_test.values)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8DbCrkRuaaP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def estimation(X_train, X_test, y_train, y_test):\n",
        "    if metadata['Libraries']==\"xgb\":\n",
        "        model = eval(metadata['estimator'])\n",
        "        predict = model.predict(xgb.DMatrix(np.array(X_test)))\n",
        "    else:\n",
        "        model = eval(metadata['estimator'])\n",
        "        print(type(model))\n",
        "        model.fit(X_train, y_train)\n",
        "        predict = model.predict(X_test)        \n",
        "        print(\"predict:\", predict)\n",
        "\n",
        "    if metadata['metric'] == \"rmse\":\n",
        "        loss = np.sqrt(mean_squared_error(y_test.values, predict))\n",
        "    elif metadata['metric'] == \"r^2\":\n",
        "        loss = r2_score(y_test, predict)\n",
        "    elif metadata['metric'] == \"logloss\":\n",
        "        predict_proba=model.predict_proba(X_test)\n",
        "        loss=multiclass_logloss(y_test, predict_proba)\n",
        "\n",
        "    print(metadata['metric'], \" :\", loss)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgFarqEZcDaV",
        "colab_type": "code",
        "outputId": "2502f4cb-015f-4568-e076-be6a3a7f9480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "waFGVH11a0j3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Accessing Google sheets\n",
        "!pip install --upgrade -q gspread\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "worksheet = gc.open('AutoKaggle').worksheet('Metadata')\n",
        "_rows = worksheet.get_all_values()\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "rows = pd.DataFrame.from_records(_rows)\n",
        "\n",
        "new_header = rows.iloc[0] #grab the first row for the header\n",
        "rows = rows[1:] #take the data less the header row\n",
        "rows.columns = new_header #set the header row as the df header"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HtYhaIZdacnb",
        "colab_type": "code",
        "outputId": "550baa21-dbc6-436f-8bbf-d54dbf015b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "cell_type": "code",
      "source": [
        "row_ids = [303, 437]\n",
        "metadata = {}\n",
        "\n",
        "\n",
        "cwd = \"/content/gdrive/My Drive/Introduction to Data Science Spring 2019 Term Project/jh5976_yd1196/\"\n",
        "for row_id in row_ids:\n",
        "  \n",
        "    # Parsing MetaData updates the metadata dict\n",
        "    metadata.clear()\n",
        "    start = time.time()\n",
        "    splitMetaData(row_id)\n",
        "    competition_dir = cwd + metadata['competition_name'] + '/data/'\n",
        "\n",
        "\n",
        "    train_df = pd.read_csv(competition_dir + 'trainData.csv' )\n",
        "    test_df = pd.read_csv(competition_dir + 'testData.csv')\n",
        "    if test_df is not None:\n",
        "        X_train, X_test, y_train, y_test = preprocessing(train_df, test_df)\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = preprocessing(train_df)\n",
        "  \n",
        "    \n",
        "    print(X_train.head(2))\n",
        "    if metadata['featureExtractor']:\n",
        "        X_train, X_test, y_train, y_test = feature_extraction(X_train, X_test, y_train, y_test)\n",
        "    \n",
        "    if metadata['feature_selector']:\n",
        "        X_train, X_test, y_train, y_test = feature_selection(X_train, X_test, y_train, y_test)\n",
        "    print(X_test.shape)\n",
        "    estimation(X_train, X_test, y_train, y_test)\n",
        "    end = time.time()\n",
        "    print('runningTimeSeconds is :'+str(end - start))\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "columns_data:  ['0', 'id', 'integer', '1', 'Open Date', 'dateTime', '2', 'City', 'unwanted', '3', 'City Group', 'categorical', '4', 'Type', 'categorical', '5', 'P1', 'integer', '6', 'P2', 'integer', '7', 'P3', 'integer', '0', 'P36', 'integer', '1', 'P37', 'integer', '2', 'revenue', 'integer']\n",
            "competition name :restaurant-revenue-prediction\n",
            "numeric_columns: ['id', 'P1', 'P2', 'P3', 'P36', 'P37']\n",
            "categorical_columns: ['City Group', 'Type']\n",
            "unwanted_columns:  ['Open Date', 'City']\n",
            "target_column: revenue\n",
            "metric:  rmse\n",
            "feature_selector:  \n",
            "featureExtractor \n",
            "estimator:  linear_model.LinearRegression()\n",
            "preprocessing:  nan processing, normalization/scaling,label encoding\n",
            "   City Group       Id        P1       P10       P11    P12       P13  \\\n",
            "0         0.0  0.00000  0.214286  0.166667  0.222222  0.375  0.444444   \n",
            "1         0.0  0.00001  0.214286  0.166667  0.000000  0.375  0.444444   \n",
            "\n",
            "        P14  P15       P16  ...       P35   P36  P37        P4        P5  \\\n",
            "0  0.066667  0.2  0.133333  ...  0.266667  0.15  0.5  0.363636  0.142857   \n",
            "1  0.000000  0.0  0.000000  ...  0.000000  0.00  0.0  0.363636  0.000000   \n",
            "\n",
            "         P6        P7        P8        P9      Type  \n",
            "0  0.111111  0.444444  0.333333  0.166667  0.666667  \n",
            "1  0.111111  0.444444  0.444444  0.166667  0.333333  \n",
            "\n",
            "[2 rows x 40 columns]\n",
            "(100000, 40)\n",
            "<class 'sklearn.linear_model.base.LinearRegression'>\n",
            "predict: [ 0.00090226  0.00078228  0.00083699 ... -0.00046104 -0.00038886\n",
            " -0.00033055]\n",
            "rmse  : 0.0005168494501827242\n",
            "runningTimeSeconds is :1.1417288780212402\n",
            "columns_data:  ['0', 'id', 'unwanted', '1', 'text', 'string', '2', 'author', 'categorical']\n",
            "competition name :spooky-author-identification\n",
            "numeric_columns: []\n",
            "categorical_columns: []\n",
            "unwanted_columns:  ['id']\n",
            "target_column: author\n",
            "metric:  logloss\n",
            "feature_selector:  \n",
            "featureExtractor CountVectorizer(lowercase=False, token_pattern=r'(?u)\\b\\w+\\b|\\,|\\.|\\;|\\:')\n",
            "estimator:  LogisticRegression(C=1.0, random_state=8)\n",
            "preprocessing:  label target, train test split\n",
            "                                    text\n",
            "15837          \"Something of that kind.\"\n",
            "12851  The general tension was horrible.\n",
            "(6993, 28039)\n",
            "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
            "predict: [2 0 0 ... 3 0 1]\n",
            "logloss  : 1.0578488198461313\n",
            "runningTimeSeconds is :14.059434175491333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zeR-pSfc9_ia",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}